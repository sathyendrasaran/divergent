{"cells": [{"cell_type": "code", "metadata": {"collapsed": true}, "source": "# @hidden_cell\nfrom pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)\n\ndef set_hadoop_config_with_credentials_e452b25d17b0410187fa1d87a5c64a19(name):\n    prefix = 'fs.swift.service.' + name\n    hconf = sc._jsc.hadoopConfiguration()\n    hconf.set(prefix + '.auth.url', 'https://identity.open.softlayer.com'+'/v3/auth/tokens')\n    hconf.set(prefix + '.auth.endpoint.prefix', 'endpoints')\n    hconf.set(prefix + '.tenant', 'dfff598f41234763839a71af72768b9e')\n    hconf.set(prefix + '.username', '0e744535c0bf4886aa955dc73a972adb')\n    hconf.set(prefix + '.password', 'gtJ]4QJ8SC?h5.e6')\n    hconf.setInt(prefix + '.http.port', 8080)\n    hconf.set(prefix + '.region', 'dallas')\n    hconf.setBoolean(prefix + '.public', True)\nname = 'keystone'\nset_hadoop_config_with_credentials_e452b25d17b0410187fa1d87a5c64a19(name)\n\ndf_data_1 = sqlContext.read.format('com.databricks.spark.csv')\\\n    .options(header='true', inferschema='true')\\\n    .load(\"swift://sparkhw.\" + name + \"/grades.csv\")\n    \ndf_data_2 = sqlContext.read.format('com.databricks.spark.csv')\\\n    .options(header='true', inferschema='true')\\\n    .load(\"swift://sparkhw.\" + name + \"/names.csv\")\n\n    ", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": "#df_data_1.printSchema()\n#df_data_2.columns\n#df_data_2.dtypes\n#df_data_2.explain\n#df_data_1.rdd.sample(False,0.2).collect()\ndf_data_1.rdd.join(df_data_2.rdd).collect()\n#df_data_1.rdd.saveAsTextFile(\"swift://sparkhw.keystone//a.txt\")\n#df_data_2.rdd.lookup(11)\n#df_data_1.select(df_data_1[\"exam_1\"]).collect()\n#sc.parallelize([1, 2, 3]).sum()\n", "execution_count": 116, "outputs": [{"data": {"text/plain": "[(8, (85, u'Dennis Lillee')),\n (12, (95, u'Rahul Dravid')),\n (4, (87, u'Garry Sobers')),\n (1, (76, u'Doug Walters')),\n (5, (69, u'Don Bradman')),\n (9, (23, u'Viv Richards')),\n (2, (90, u'Rohan Kanhai')),\n (10, (71, u'VVS Laxman')),\n (6, (90, u'Ian Chappell')),\n (11, (65, u'Michael Holding')),\n (3, (45, u'Peter Pollock')),\n (7, (81, u'Andy Roberts'))]"}, "metadata": {}, "execution_count": 116, "output_type": "execute_result"}]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": "#2a df_data_2.where(df_data_2.student_name.startswith(\"D\") == True).count()\n#2b \n#2c df_data_1.agg({\"exam_1\":\"avg\"}).collect()\n#2d \n", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": "#2c \ndf_data_1.agg({\"exam_1\":\"avg\"}).collect()", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": "sqlContext.sql(\"select * from stu order by student_id asc\").collect()", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": "df_data_1.registerTempTable(\"stu\")\nsqlContext.sql(\"select * from stu\").collect()", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": "ctable = df_data_1.join(df_data_2,df_data_1.student_id == df_data_2.student_id)\nexam_average = ((ctable.exam_1+ctable.exam_2+ctable.exam_3)/3).alias(\"exam_average\")\ndef mtog(mark):\n    if mark > 89 : \n        return 'A' \n    elif mark > 79 :\n        return 'B' \n    elif mark > 69 :\n        return 'C'\n    elif mark > 59 :\n        return 'D'  \n    else :\n        return 'F'\ngradefn = pyspark.sql.functions.udf(mtog)\ngrade = gradefn(exam_average).alias(\"grade\")\ndft = ctable.select(ctable.student_name,exam_average,grade)\n#dft.orderBy(dft['exam_average'],ascending = False).show()\ndft.sort(dft.exam_average.desc()).show()", "execution_count": 118, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---------------+------------------+-----+\n|   student_name|      exam_average|grade|\n+---------------+------------------+-----+\n|   Rahul Dravid| 94.66666666666667|    A|\n|   Ian Chappell| 93.66666666666667|    A|\n|   Rohan Kanhai| 92.66666666666667|    A|\n|   Andy Roberts| 86.33333333333333|    B|\n|  Dennis Lillee| 85.66666666666667|    B|\n|   Garry Sobers| 85.66666666666667|    B|\n|   Doug Walters|              79.0|    C|\n|     VVS Laxman| 73.66666666666667|    C|\n|    Don Bradman| 66.66666666666667|    D|\n|Michael Holding| 65.66666666666667|    D|\n|  Peter Pollock|41.333333333333336|    F|\n|   Viv Richards|36.333333333333336|    F|\n+---------------+------------------+-----+\n\n"}]}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": "", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": "", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": "", "execution_count": null, "outputs": []}], "nbformat_minor": 0, "metadata": {"kernelspec": {"display_name": "Python 2 with Spark 1.6", "language": "python", "name": "python2"}, "language_info": {"version": "2.7.11", "codemirror_mode": {"version": 2, "name": "ipython"}, "mimetype": "text/x-python", "nbconvert_exporter": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "name": "python"}}, "nbformat": 4}